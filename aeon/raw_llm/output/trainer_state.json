{
  "best_global_step": 1240,
  "best_metric": 5.947650909423828,
  "best_model_checkpoint": "./aeon/raw_llm/output/checkpoint-1240",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1240,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08080808080808081,
      "grad_norm": 2.7549877166748047,
      "learning_rate": 9.927419354838711e-06,
      "loss": 10.1164,
      "step": 10
    },
    {
      "epoch": 0.16161616161616163,
      "grad_norm": 2.4918603897094727,
      "learning_rate": 9.846774193548388e-06,
      "loss": 9.5922,
      "step": 20
    },
    {
      "epoch": 0.24242424242424243,
      "grad_norm": 2.3752777576446533,
      "learning_rate": 9.766129032258065e-06,
      "loss": 9.3403,
      "step": 30
    },
    {
      "epoch": 0.32323232323232326,
      "grad_norm": 2.085888624191284,
      "learning_rate": 9.685483870967743e-06,
      "loss": 9.1413,
      "step": 40
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 1.998303771018982,
      "learning_rate": 9.60483870967742e-06,
      "loss": 8.9964,
      "step": 50
    },
    {
      "epoch": 0.48484848484848486,
      "grad_norm": 1.9081175327301025,
      "learning_rate": 9.524193548387098e-06,
      "loss": 8.8788,
      "step": 60
    },
    {
      "epoch": 0.5656565656565656,
      "grad_norm": 2.0128629207611084,
      "learning_rate": 9.443548387096774e-06,
      "loss": 8.7628,
      "step": 70
    },
    {
      "epoch": 0.6464646464646465,
      "grad_norm": 1.911892294883728,
      "learning_rate": 9.362903225806452e-06,
      "loss": 8.6755,
      "step": 80
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 2.052103042602539,
      "learning_rate": 9.28225806451613e-06,
      "loss": 8.5744,
      "step": 90
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 1.9277037382125854,
      "learning_rate": 9.201612903225807e-06,
      "loss": 8.4891,
      "step": 100
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.839767336845398,
      "learning_rate": 9.120967741935485e-06,
      "loss": 8.4061,
      "step": 110
    },
    {
      "epoch": 0.9696969696969697,
      "grad_norm": 1.8562312126159668,
      "learning_rate": 9.040322580645162e-06,
      "loss": 8.3367,
      "step": 120
    },
    {
      "epoch": 1.0,
      "eval_loss": 7.998798847198486,
      "eval_runtime": 36.9979,
      "eval_samples_per_second": 14.568,
      "eval_steps_per_second": 1.838,
      "step": 124
    },
    {
      "epoch": 1.0484848484848486,
      "grad_norm": 1.831526279449463,
      "learning_rate": 8.95967741935484e-06,
      "loss": 8.2531,
      "step": 130
    },
    {
      "epoch": 1.1292929292929292,
      "grad_norm": 1.8560384511947632,
      "learning_rate": 8.879032258064517e-06,
      "loss": 8.1571,
      "step": 140
    },
    {
      "epoch": 1.2101010101010101,
      "grad_norm": 1.758781909942627,
      "learning_rate": 8.798387096774195e-06,
      "loss": 8.0935,
      "step": 150
    },
    {
      "epoch": 1.290909090909091,
      "grad_norm": 1.8488324880599976,
      "learning_rate": 8.717741935483872e-06,
      "loss": 8.0321,
      "step": 160
    },
    {
      "epoch": 1.3717171717171717,
      "grad_norm": 1.7859691381454468,
      "learning_rate": 8.63709677419355e-06,
      "loss": 7.9604,
      "step": 170
    },
    {
      "epoch": 1.4525252525252526,
      "grad_norm": 2.0418756008148193,
      "learning_rate": 8.556451612903226e-06,
      "loss": 7.8906,
      "step": 180
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 1.7125669717788696,
      "learning_rate": 8.475806451612903e-06,
      "loss": 7.8419,
      "step": 190
    },
    {
      "epoch": 1.614141414141414,
      "grad_norm": 1.6851330995559692,
      "learning_rate": 8.395161290322581e-06,
      "loss": 7.7593,
      "step": 200
    },
    {
      "epoch": 1.694949494949495,
      "grad_norm": 1.8203537464141846,
      "learning_rate": 8.314516129032258e-06,
      "loss": 7.7201,
      "step": 210
    },
    {
      "epoch": 1.7757575757575759,
      "grad_norm": 1.6260727643966675,
      "learning_rate": 8.233870967741936e-06,
      "loss": 7.634,
      "step": 220
    },
    {
      "epoch": 1.8565656565656565,
      "grad_norm": 1.8328849077224731,
      "learning_rate": 8.153225806451614e-06,
      "loss": 7.6125,
      "step": 230
    },
    {
      "epoch": 1.9373737373737374,
      "grad_norm": 1.700860857963562,
      "learning_rate": 8.07258064516129e-06,
      "loss": 7.5414,
      "step": 240
    },
    {
      "epoch": 2.0,
      "eval_loss": 7.223698139190674,
      "eval_runtime": 36.9422,
      "eval_samples_per_second": 14.59,
      "eval_steps_per_second": 1.841,
      "step": 248
    },
    {
      "epoch": 2.0161616161616163,
      "grad_norm": 1.6873172521591187,
      "learning_rate": 7.991935483870969e-06,
      "loss": 7.4664,
      "step": 250
    },
    {
      "epoch": 2.096969696969697,
      "grad_norm": 1.6676019430160522,
      "learning_rate": 7.911290322580646e-06,
      "loss": 7.4169,
      "step": 260
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 1.5796581506729126,
      "learning_rate": 7.830645161290324e-06,
      "loss": 7.3949,
      "step": 270
    },
    {
      "epoch": 2.2585858585858585,
      "grad_norm": 1.6003180742263794,
      "learning_rate": 7.75e-06,
      "loss": 7.35,
      "step": 280
    },
    {
      "epoch": 2.3393939393939394,
      "grad_norm": 1.6806843280792236,
      "learning_rate": 7.669354838709679e-06,
      "loss": 7.3076,
      "step": 290
    },
    {
      "epoch": 2.4202020202020202,
      "grad_norm": 1.5949347019195557,
      "learning_rate": 7.588709677419356e-06,
      "loss": 7.2468,
      "step": 300
    },
    {
      "epoch": 2.501010101010101,
      "grad_norm": 1.4640804529190063,
      "learning_rate": 7.508064516129033e-06,
      "loss": 7.2258,
      "step": 310
    },
    {
      "epoch": 2.581818181818182,
      "grad_norm": 1.6529444456100464,
      "learning_rate": 7.427419354838711e-06,
      "loss": 7.1569,
      "step": 320
    },
    {
      "epoch": 2.6626262626262625,
      "grad_norm": 1.5194065570831299,
      "learning_rate": 7.346774193548387e-06,
      "loss": 7.1516,
      "step": 330
    },
    {
      "epoch": 2.7434343434343433,
      "grad_norm": 1.3935270309448242,
      "learning_rate": 7.266129032258065e-06,
      "loss": 7.1062,
      "step": 340
    },
    {
      "epoch": 2.824242424242424,
      "grad_norm": 1.4085973501205444,
      "learning_rate": 7.185483870967742e-06,
      "loss": 7.0402,
      "step": 350
    },
    {
      "epoch": 2.905050505050505,
      "grad_norm": 1.6181014776229858,
      "learning_rate": 7.1048387096774195e-06,
      "loss": 7.008,
      "step": 360
    },
    {
      "epoch": 2.985858585858586,
      "grad_norm": 1.6591883897781372,
      "learning_rate": 7.024193548387097e-06,
      "loss": 6.984,
      "step": 370
    },
    {
      "epoch": 3.0,
      "eval_loss": 6.742894172668457,
      "eval_runtime": 36.9902,
      "eval_samples_per_second": 14.571,
      "eval_steps_per_second": 1.838,
      "step": 372
    },
    {
      "epoch": 3.0646464646464646,
      "grad_norm": 1.633509635925293,
      "learning_rate": 6.943548387096774e-06,
      "loss": 6.9599,
      "step": 380
    },
    {
      "epoch": 3.1454545454545455,
      "grad_norm": 1.3637782335281372,
      "learning_rate": 6.862903225806452e-06,
      "loss": 6.9496,
      "step": 390
    },
    {
      "epoch": 3.2262626262626264,
      "grad_norm": 1.3345774412155151,
      "learning_rate": 6.78225806451613e-06,
      "loss": 6.8771,
      "step": 400
    },
    {
      "epoch": 3.3070707070707073,
      "grad_norm": 1.4315580129623413,
      "learning_rate": 6.701612903225807e-06,
      "loss": 6.8654,
      "step": 410
    },
    {
      "epoch": 3.3878787878787877,
      "grad_norm": 1.7242727279663086,
      "learning_rate": 6.620967741935485e-06,
      "loss": 6.8252,
      "step": 420
    },
    {
      "epoch": 3.4686868686868686,
      "grad_norm": 1.463613510131836,
      "learning_rate": 6.540322580645162e-06,
      "loss": 6.7965,
      "step": 430
    },
    {
      "epoch": 3.5494949494949495,
      "grad_norm": 1.4446238279342651,
      "learning_rate": 6.4596774193548396e-06,
      "loss": 6.7761,
      "step": 440
    },
    {
      "epoch": 3.6303030303030304,
      "grad_norm": 1.539049506187439,
      "learning_rate": 6.379032258064517e-06,
      "loss": 6.7783,
      "step": 450
    },
    {
      "epoch": 3.7111111111111112,
      "grad_norm": 1.602628231048584,
      "learning_rate": 6.298387096774194e-06,
      "loss": 6.7484,
      "step": 460
    },
    {
      "epoch": 3.7919191919191917,
      "grad_norm": 1.254321813583374,
      "learning_rate": 6.217741935483872e-06,
      "loss": 6.7148,
      "step": 470
    },
    {
      "epoch": 3.8727272727272726,
      "grad_norm": 1.4446868896484375,
      "learning_rate": 6.137096774193549e-06,
      "loss": 6.7105,
      "step": 480
    },
    {
      "epoch": 3.9535353535353535,
      "grad_norm": 1.8789966106414795,
      "learning_rate": 6.056451612903226e-06,
      "loss": 6.6942,
      "step": 490
    },
    {
      "epoch": 4.0,
      "eval_loss": 6.447541236877441,
      "eval_runtime": 36.8003,
      "eval_samples_per_second": 14.647,
      "eval_steps_per_second": 1.848,
      "step": 496
    },
    {
      "epoch": 4.0323232323232325,
      "grad_norm": 1.4547743797302246,
      "learning_rate": 5.975806451612903e-06,
      "loss": 6.6484,
      "step": 500
    },
    {
      "epoch": 4.113131313131313,
      "grad_norm": 1.3570976257324219,
      "learning_rate": 5.8951612903225805e-06,
      "loss": 6.6338,
      "step": 510
    },
    {
      "epoch": 4.193939393939394,
      "grad_norm": 1.3068245649337769,
      "learning_rate": 5.814516129032258e-06,
      "loss": 6.6054,
      "step": 520
    },
    {
      "epoch": 4.274747474747475,
      "grad_norm": 1.5332942008972168,
      "learning_rate": 5.733870967741936e-06,
      "loss": 6.6055,
      "step": 530
    },
    {
      "epoch": 4.355555555555555,
      "grad_norm": 1.4460629224777222,
      "learning_rate": 5.6532258064516136e-06,
      "loss": 6.5945,
      "step": 540
    },
    {
      "epoch": 4.4363636363636365,
      "grad_norm": 1.3089998960494995,
      "learning_rate": 5.572580645161291e-06,
      "loss": 6.5727,
      "step": 550
    },
    {
      "epoch": 4.517171717171717,
      "grad_norm": 1.3930637836456299,
      "learning_rate": 5.491935483870968e-06,
      "loss": 6.5456,
      "step": 560
    },
    {
      "epoch": 4.597979797979798,
      "grad_norm": 1.2833194732666016,
      "learning_rate": 5.411290322580646e-06,
      "loss": 6.5218,
      "step": 570
    },
    {
      "epoch": 4.678787878787879,
      "grad_norm": 1.4118601083755493,
      "learning_rate": 5.330645161290323e-06,
      "loss": 6.4907,
      "step": 580
    },
    {
      "epoch": 4.759595959595959,
      "grad_norm": 1.1893409490585327,
      "learning_rate": 5.2500000000000006e-06,
      "loss": 6.4851,
      "step": 590
    },
    {
      "epoch": 4.8404040404040405,
      "grad_norm": 1.1706770658493042,
      "learning_rate": 5.169354838709678e-06,
      "loss": 6.483,
      "step": 600
    },
    {
      "epoch": 4.921212121212121,
      "grad_norm": 1.0535128116607666,
      "learning_rate": 5.088709677419355e-06,
      "loss": 6.4487,
      "step": 610
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.2396434545516968,
      "learning_rate": 5.008064516129033e-06,
      "loss": 6.4389,
      "step": 620
    },
    {
      "epoch": 5.0,
      "eval_loss": 6.253062725067139,
      "eval_runtime": 36.9978,
      "eval_samples_per_second": 14.568,
      "eval_steps_per_second": 1.838,
      "step": 620
    },
    {
      "epoch": 5.08080808080808,
      "grad_norm": 1.1251533031463623,
      "learning_rate": 4.92741935483871e-06,
      "loss": 6.4124,
      "step": 630
    },
    {
      "epoch": 5.161616161616162,
      "grad_norm": 1.348185420036316,
      "learning_rate": 4.8467741935483876e-06,
      "loss": 6.4122,
      "step": 640
    },
    {
      "epoch": 5.242424242424242,
      "grad_norm": 1.450770616531372,
      "learning_rate": 4.766129032258065e-06,
      "loss": 6.3827,
      "step": 650
    },
    {
      "epoch": 5.3232323232323235,
      "grad_norm": 1.3097436428070068,
      "learning_rate": 4.685483870967742e-06,
      "loss": 6.4017,
      "step": 660
    },
    {
      "epoch": 5.404040404040404,
      "grad_norm": 1.3904038667678833,
      "learning_rate": 4.60483870967742e-06,
      "loss": 6.3786,
      "step": 670
    },
    {
      "epoch": 5.484848484848484,
      "grad_norm": 1.0447206497192383,
      "learning_rate": 4.524193548387097e-06,
      "loss": 6.3767,
      "step": 680
    },
    {
      "epoch": 5.565656565656566,
      "grad_norm": 1.2832491397857666,
      "learning_rate": 4.4435483870967745e-06,
      "loss": 6.3493,
      "step": 690
    },
    {
      "epoch": 5.646464646464646,
      "grad_norm": 1.2523434162139893,
      "learning_rate": 4.362903225806452e-06,
      "loss": 6.3647,
      "step": 700
    },
    {
      "epoch": 5.7272727272727275,
      "grad_norm": 1.5601404905319214,
      "learning_rate": 4.282258064516129e-06,
      "loss": 6.3568,
      "step": 710
    },
    {
      "epoch": 5.808080808080808,
      "grad_norm": 1.4108953475952148,
      "learning_rate": 4.201612903225807e-06,
      "loss": 6.3407,
      "step": 720
    },
    {
      "epoch": 5.888888888888889,
      "grad_norm": 1.282169222831726,
      "learning_rate": 4.120967741935484e-06,
      "loss": 6.3175,
      "step": 730
    },
    {
      "epoch": 5.96969696969697,
      "grad_norm": 1.1190751791000366,
      "learning_rate": 4.0403225806451615e-06,
      "loss": 6.3129,
      "step": 740
    },
    {
      "epoch": 6.0,
      "eval_loss": 6.124902248382568,
      "eval_runtime": 36.8094,
      "eval_samples_per_second": 14.643,
      "eval_steps_per_second": 1.847,
      "step": 744
    },
    {
      "epoch": 6.048484848484849,
      "grad_norm": 1.1049050092697144,
      "learning_rate": 3.959677419354839e-06,
      "loss": 6.2867,
      "step": 750
    },
    {
      "epoch": 6.129292929292929,
      "grad_norm": 1.1922415494918823,
      "learning_rate": 3.879032258064516e-06,
      "loss": 6.2845,
      "step": 760
    },
    {
      "epoch": 6.21010101010101,
      "grad_norm": 1.225593090057373,
      "learning_rate": 3.7983870967741937e-06,
      "loss": 6.2913,
      "step": 770
    },
    {
      "epoch": 6.290909090909091,
      "grad_norm": 1.1155064105987549,
      "learning_rate": 3.717741935483871e-06,
      "loss": 6.2721,
      "step": 780
    },
    {
      "epoch": 6.3717171717171714,
      "grad_norm": 1.2161403894424438,
      "learning_rate": 3.6370967741935485e-06,
      "loss": 6.268,
      "step": 790
    },
    {
      "epoch": 6.452525252525253,
      "grad_norm": 1.2880977392196655,
      "learning_rate": 3.5564516129032264e-06,
      "loss": 6.2563,
      "step": 800
    },
    {
      "epoch": 6.533333333333333,
      "grad_norm": 1.0515127182006836,
      "learning_rate": 3.4758064516129038e-06,
      "loss": 6.2493,
      "step": 810
    },
    {
      "epoch": 6.6141414141414145,
      "grad_norm": 1.1771091222763062,
      "learning_rate": 3.395161290322581e-06,
      "loss": 6.2359,
      "step": 820
    },
    {
      "epoch": 6.694949494949495,
      "grad_norm": 1.2945172786712646,
      "learning_rate": 3.3145161290322586e-06,
      "loss": 6.229,
      "step": 830
    },
    {
      "epoch": 6.775757575757575,
      "grad_norm": 1.2111390829086304,
      "learning_rate": 3.2338709677419355e-06,
      "loss": 6.2362,
      "step": 840
    },
    {
      "epoch": 6.856565656565657,
      "grad_norm": 1.2313435077667236,
      "learning_rate": 3.153225806451613e-06,
      "loss": 6.2118,
      "step": 850
    },
    {
      "epoch": 6.937373737373737,
      "grad_norm": 1.054140329360962,
      "learning_rate": 3.0725806451612903e-06,
      "loss": 6.2211,
      "step": 860
    },
    {
      "epoch": 7.0,
      "eval_loss": 6.043557643890381,
      "eval_runtime": 36.8308,
      "eval_samples_per_second": 14.634,
      "eval_steps_per_second": 1.846,
      "step": 868
    },
    {
      "epoch": 7.016161616161616,
      "grad_norm": 1.4594197273254395,
      "learning_rate": 2.991935483870968e-06,
      "loss": 6.198,
      "step": 870
    },
    {
      "epoch": 7.096969696969697,
      "grad_norm": 1.0232454538345337,
      "learning_rate": 2.9112903225806456e-06,
      "loss": 6.219,
      "step": 880
    },
    {
      "epoch": 7.177777777777778,
      "grad_norm": 1.2748878002166748,
      "learning_rate": 2.830645161290323e-06,
      "loss": 6.2123,
      "step": 890
    },
    {
      "epoch": 7.2585858585858585,
      "grad_norm": 1.0424705743789673,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 6.1891,
      "step": 900
    },
    {
      "epoch": 7.33939393939394,
      "grad_norm": 1.1884340047836304,
      "learning_rate": 2.6693548387096773e-06,
      "loss": 6.1927,
      "step": 910
    },
    {
      "epoch": 7.42020202020202,
      "grad_norm": 1.2932053804397583,
      "learning_rate": 2.5887096774193547e-06,
      "loss": 6.202,
      "step": 920
    },
    {
      "epoch": 7.501010101010101,
      "grad_norm": 1.1244488954544067,
      "learning_rate": 2.5080645161290325e-06,
      "loss": 6.1886,
      "step": 930
    },
    {
      "epoch": 7.581818181818182,
      "grad_norm": 1.0929127931594849,
      "learning_rate": 2.42741935483871e-06,
      "loss": 6.1694,
      "step": 940
    },
    {
      "epoch": 7.6626262626262625,
      "grad_norm": 1.3206408023834229,
      "learning_rate": 2.3467741935483873e-06,
      "loss": 6.1645,
      "step": 950
    },
    {
      "epoch": 7.743434343434344,
      "grad_norm": 1.2773839235305786,
      "learning_rate": 2.2661290322580647e-06,
      "loss": 6.1497,
      "step": 960
    },
    {
      "epoch": 7.824242424242424,
      "grad_norm": 1.1713773012161255,
      "learning_rate": 2.185483870967742e-06,
      "loss": 6.1446,
      "step": 970
    },
    {
      "epoch": 7.9050505050505055,
      "grad_norm": 1.111093521118164,
      "learning_rate": 2.1048387096774195e-06,
      "loss": 6.1446,
      "step": 980
    },
    {
      "epoch": 7.985858585858586,
      "grad_norm": 1.0114221572875977,
      "learning_rate": 2.024193548387097e-06,
      "loss": 6.1225,
      "step": 990
    },
    {
      "epoch": 8.0,
      "eval_loss": 5.9892802238464355,
      "eval_runtime": 36.9439,
      "eval_samples_per_second": 14.59,
      "eval_steps_per_second": 1.841,
      "step": 992
    },
    {
      "epoch": 8.064646464646465,
      "grad_norm": 1.1468112468719482,
      "learning_rate": 1.9435483870967743e-06,
      "loss": 6.156,
      "step": 1000
    },
    {
      "epoch": 8.145454545454545,
      "grad_norm": 1.1002295017242432,
      "learning_rate": 1.8629032258064517e-06,
      "loss": 6.1596,
      "step": 1010
    },
    {
      "epoch": 8.226262626262626,
      "grad_norm": 1.0551528930664062,
      "learning_rate": 1.7822580645161291e-06,
      "loss": 6.1235,
      "step": 1020
    },
    {
      "epoch": 8.307070707070707,
      "grad_norm": 1.3434491157531738,
      "learning_rate": 1.7016129032258065e-06,
      "loss": 6.1815,
      "step": 1030
    },
    {
      "epoch": 8.387878787878789,
      "grad_norm": 1.2170360088348389,
      "learning_rate": 1.6209677419354842e-06,
      "loss": 6.1504,
      "step": 1040
    },
    {
      "epoch": 8.468686868686868,
      "grad_norm": 1.1311726570129395,
      "learning_rate": 1.5403225806451613e-06,
      "loss": 6.1314,
      "step": 1050
    },
    {
      "epoch": 8.54949494949495,
      "grad_norm": 1.0730944871902466,
      "learning_rate": 1.4596774193548387e-06,
      "loss": 6.1205,
      "step": 1060
    },
    {
      "epoch": 8.63030303030303,
      "grad_norm": 1.0188969373703003,
      "learning_rate": 1.3790322580645163e-06,
      "loss": 6.0909,
      "step": 1070
    },
    {
      "epoch": 8.71111111111111,
      "grad_norm": 1.0302799940109253,
      "learning_rate": 1.2983870967741937e-06,
      "loss": 6.1052,
      "step": 1080
    },
    {
      "epoch": 8.791919191919192,
      "grad_norm": 0.9908244013786316,
      "learning_rate": 1.2177419354838711e-06,
      "loss": 6.1187,
      "step": 1090
    },
    {
      "epoch": 8.872727272727273,
      "grad_norm": 1.2121282815933228,
      "learning_rate": 1.1370967741935485e-06,
      "loss": 6.132,
      "step": 1100
    },
    {
      "epoch": 8.953535353535354,
      "grad_norm": 1.0671707391738892,
      "learning_rate": 1.056451612903226e-06,
      "loss": 6.0758,
      "step": 1110
    },
    {
      "epoch": 9.0,
      "eval_loss": 5.958165645599365,
      "eval_runtime": 36.8254,
      "eval_samples_per_second": 14.637,
      "eval_steps_per_second": 1.847,
      "step": 1116
    },
    {
      "epoch": 9.032323232323233,
      "grad_norm": 1.0404354333877563,
      "learning_rate": 9.758064516129033e-07,
      "loss": 6.1064,
      "step": 1120
    },
    {
      "epoch": 9.113131313131314,
      "grad_norm": 1.0478274822235107,
      "learning_rate": 8.951612903225807e-07,
      "loss": 6.1242,
      "step": 1130
    },
    {
      "epoch": 9.193939393939393,
      "grad_norm": 1.086634874343872,
      "learning_rate": 8.145161290322581e-07,
      "loss": 6.0967,
      "step": 1140
    },
    {
      "epoch": 9.274747474747475,
      "grad_norm": 1.069124698638916,
      "learning_rate": 7.338709677419354e-07,
      "loss": 6.1071,
      "step": 1150
    },
    {
      "epoch": 9.355555555555556,
      "grad_norm": 0.9532150626182556,
      "learning_rate": 6.532258064516129e-07,
      "loss": 6.1171,
      "step": 1160
    },
    {
      "epoch": 9.436363636363636,
      "grad_norm": 0.9500951766967773,
      "learning_rate": 5.725806451612903e-07,
      "loss": 6.0802,
      "step": 1170
    },
    {
      "epoch": 9.517171717171717,
      "grad_norm": 1.189302921295166,
      "learning_rate": 4.919354838709677e-07,
      "loss": 6.1031,
      "step": 1180
    },
    {
      "epoch": 9.597979797979798,
      "grad_norm": 0.9877744317054749,
      "learning_rate": 4.112903225806452e-07,
      "loss": 6.1007,
      "step": 1190
    },
    {
      "epoch": 9.67878787878788,
      "grad_norm": 0.9789785742759705,
      "learning_rate": 3.3064516129032264e-07,
      "loss": 6.104,
      "step": 1200
    },
    {
      "epoch": 9.75959595959596,
      "grad_norm": 0.9495121836662292,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 6.1148,
      "step": 1210
    },
    {
      "epoch": 9.84040404040404,
      "grad_norm": 0.9270535707473755,
      "learning_rate": 1.6935483870967744e-07,
      "loss": 6.1116,
      "step": 1220
    },
    {
      "epoch": 9.921212121212122,
      "grad_norm": 0.9871724843978882,
      "learning_rate": 8.870967741935485e-08,
      "loss": 6.0921,
      "step": 1230
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.0721850395202637,
      "learning_rate": 8.064516129032259e-09,
      "loss": 6.0807,
      "step": 1240
    },
    {
      "epoch": 10.0,
      "eval_loss": 5.947650909423828,
      "eval_runtime": 36.7921,
      "eval_samples_per_second": 14.65,
      "eval_steps_per_second": 1.848,
      "step": 1240
    }
  ],
  "logging_steps": 10,
  "max_steps": 1240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8750324432896e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
